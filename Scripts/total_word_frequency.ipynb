{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer() #create lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shirinharandi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv('../data/processedDict.csv')\n",
    "dictionary['word'] = dictionary['word'].apply(lambda x: lem.lemmatize(x, pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE LATER\n",
    "# mask = (reviews['date'] >= '2013-01-01') & (reviews['date'] < '2014-01-01')\n",
    "# reviews = reviews.loc[mask].copy()\n",
    "# reviews[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_trends_nice_og(reviews):\n",
    "    \n",
    "    def get_unique_words(rev):\n",
    "        \n",
    "        allwords = rev['comments'].tolist()\n",
    "        allwords = \" \".join(allwords)\n",
    "        unique_words = set(allwords.split(' '))\n",
    "\n",
    "        unique_words = list(unique_words)\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "\n",
    "        ls = []\n",
    "        for word in unique_words:\n",
    "            word = ''.join([i for i in word if not i.isdigit()])\n",
    "            ls += [word]\n",
    "        unique_words= ls\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "        unique_words = list(dict.fromkeys(unique_words))\n",
    "        return unique_words\n",
    "    \n",
    "    def get_masked_reviews(start_year, end_year):\n",
    "        mask = (reviews['date'] >= start_year) & (reviews['date'] < end_year)\n",
    "        return reviews.loc[mask].copy()\n",
    "    \n",
    "#     def get_reviews_list(rev):\n",
    "        \n",
    "    \n",
    "    old_reviews =  get_masked_reviews('2013-01-01', '2014-01-01')\n",
    "#     print(old_reviews)\n",
    "    new_reviews =  get_masked_reviews('2017-01-01', '2018-01-01')\n",
    "\n",
    "    start_year_words = get_unique_words(old_reviews)\n",
    "    end_year_words = get_unique_words(new_reviews)\n",
    "    \n",
    "    old_reviews_list = old_reviews['comments'].tolist()\n",
    "    new_reviews_list = new_reviews['comments'].tolist()\n",
    "\n",
    "#     print(new_reviews_list)\n",
    "    \n",
    "    def get_freq(word, rev):\n",
    "        total = 0.0\n",
    "        rev = list(rev)\n",
    "        for r in rev:\n",
    "            r = r.split()\n",
    "            total += math.log(1 + r.count(word))\n",
    "        return total\n",
    "\n",
    "    column_names = [\"word\", \"old_frequency\", \"new_frequency\"]\n",
    "    out = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    old_total = 0.0\n",
    "    for word in start_year_words:\n",
    "        f = get_freq(word, old_reviews_list)\n",
    "        old_total += f\n",
    "        out = out.append({'word': word, 'old_frequency': f, \"new_frequency\": 0.0}, ignore_index=True)\n",
    "        \n",
    "    new_total = 0.0\n",
    "    for word in end_year_words:\n",
    "        f = get_freq(word, new_reviews_list)\n",
    "        new_total += f\n",
    "        if word in start_year_words:\n",
    "            ind = out.index[out['word']==word]\n",
    "            out.loc[ind,\"new_frequency\"] = f\n",
    "        else:\n",
    "            out = out.append({'word': word, 'old_frequency': 0.0, 'new_frequency': f}, ignore_index=True)\n",
    "    \n",
    "    out[\"old_sum_count\"] = old_total\n",
    "    out[\"new_sum_count\"] = new_total\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "killme = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trends_nice(reviews):\n",
    "    \n",
    "    def get_unique_words(rev):\n",
    "        \n",
    "        allwords = rev['comments'].tolist()\n",
    "        allwords = \" \".join(allwords)\n",
    "        unique_words = set(allwords.split(' '))\n",
    "\n",
    "        unique_words = list(unique_words)\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "\n",
    "        ls = []\n",
    "        for word in unique_words:\n",
    "            word = ''.join([i for i in word if not i.isdigit()])\n",
    "            ls += [word]\n",
    "        unique_words= ls\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "        unique_words = list(dict.fromkeys(unique_words))\n",
    "        return unique_words\n",
    "    \n",
    "    def get_masked_reviews(start_year, end_year):\n",
    "        mask = (reviews['date'] >= start_year) & (reviews['date'] < end_year)\n",
    "        return reviews.loc[mask].copy()\n",
    "    \n",
    "#     def get_reviews_list(rev):\n",
    "        \n",
    "    \n",
    "    old_reviews =  get_masked_reviews('2013-01-01', '2014-01-01')\n",
    "#     print(old_reviews)\n",
    "    new_reviews =  get_masked_reviews('2017-01-01', '2018-01-01')\n",
    "\n",
    "    start_year_words = get_unique_words(old_reviews)\n",
    "    end_year_words = get_unique_words(new_reviews)\n",
    "    \n",
    "    in_first = set(start_year_words)\n",
    "    in_second = set(end_year_words)\n",
    "\n",
    "    in_second_but_not_in_first = in_second - in_first\n",
    "\n",
    "    total_words_in_reviews = start_year_words + list(in_second_but_not_in_first)\n",
    "    killme = total_words_in_reviews\n",
    "    \n",
    "    old_reviews_list = old_reviews['comments'].tolist()\n",
    "    new_reviews_list = new_reviews['comments'].tolist()\n",
    "\n",
    "\n",
    "    def get_freq(word, rev):\n",
    "        total = 0.0\n",
    "        rev = list(rev)\n",
    "        for r in rev:\n",
    "            r = r.split()\n",
    "            total += math.log(1 + r.count(word))\n",
    "        return total\n",
    "\n",
    "    column_names = [\"word\", \"old_frequency\", \"new_frequency\"]\n",
    "    out = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    old_total = 0.0\n",
    "    new_total = 0.0\n",
    "    for word in total_words_in_reviews:\n",
    "        f = get_freq(word, old_reviews_list)\n",
    "        old_total += f\n",
    "#         print(f)\n",
    "#         print(word)\n",
    "        f2 = get_freq(word, new_reviews_list)\n",
    "        new_total += f2\n",
    "        out = out.append({'word': word, 'old_frequency': f, \"new_frequency\": f2}, ignore_index=True)\n",
    "        \n",
    "    out[\"old_sum_count\"] = old_total\n",
    "    out[\"new_sum_count\"] = new_total\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_words = dictionary['word'].tolist()\n",
    "dictionary_words = list(set(dictionary_words))\n",
    "# dictionary_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "cities = [\"tokyo\", \"belize\", \"santiago\", \"taipei\", \"singapore\", \"beijing\", \"hong_kong\", \"mexico_city\", \"buenos_aires\", \"rio\"]\n",
    "# cities = [\"manchester\", \"tokyo\"]\n",
    "\n",
    "column_names = [\"word\", \"old_frequency\", \"new_frequency\",\"old_sum_count\", \"new_sum_count\",\"city\", \"Ofrequency\", \"Nfrequency\",\"freq\", \"gain\", \"licia_gain\"]\n",
    "big_out = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for c in cities: \n",
    "    path = \"/Users/shirinharandi/Desktop/COMP0031/Data/en_reviews/{}_en.csv\".format(c)\n",
    "    filepath = path\n",
    "    city_name = c\n",
    "    reviews = pd.read_csv(filepath)\n",
    "\n",
    "    table = str.maketrans('', '', string.punctuation) #mapping to strip punctuation in review\n",
    "\n",
    "    #strip punct of each review -> lemmatise -> output is list of words so join into sentences\n",
    "    reviews['comments'] = reviews.comments.apply(lambda review: ' '.join(map(str, [lem.lemmatize(word.translate(table), pos='n') for word in review.lower().split()])))\n",
    "    reviews['date'] = pd.to_datetime(reviews['date'])\n",
    "    \n",
    "    out = get_trends_nice_og(reviews)\n",
    "    \n",
    "    test = out[out['word'].isin(dictionary_words)]\n",
    "\n",
    "    test['city'] = city_name\n",
    "    test['Ofrequency'] = test['old_frequency'] / test['old_sum_count']\n",
    "    test['Nfrequency'] = test['new_frequency'] / test['new_sum_count']\n",
    "    test['freq'] = (test['Nfrequency'] + test['Ofrequency'])/2\n",
    "    test['gain'] = np.where(test['Ofrequency'] == 0, 1000 ,test['Nfrequency'] / test['Ofrequency'])\n",
    "    test['licia_gain'] = np.where(test['Ofrequency'] == 0, 1000 ,test['new_frequency'] / test['old_frequency'])\n",
    "    \n",
    "#     print(test)\n",
    "    big_out = pd.concat([big_out, test], ignore_index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>old_frequency</th>\n",
       "      <th>new_frequency</th>\n",
       "      <th>old_sum_count</th>\n",
       "      <th>new_sum_count</th>\n",
       "      <th>city</th>\n",
       "      <th>Ofrequency</th>\n",
       "      <th>Nfrequency</th>\n",
       "      <th>freq</th>\n",
       "      <th>gain</th>\n",
       "      <th>licia_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedroom</td>\n",
       "      <td>14.203870</td>\n",
       "      <td>516.607518</td>\n",
       "      <td>19587.067856</td>\n",
       "      <td>1.024215e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>36.370898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>centrally</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>129.330841</td>\n",
       "      <td>19587.067856</td>\n",
       "      <td>1.024215e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1.784124</td>\n",
       "      <td>93.292481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quiet</td>\n",
       "      <td>42.281978</td>\n",
       "      <td>3379.334336</td>\n",
       "      <td>19587.067856</td>\n",
       "      <td>1.024215e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>1.528460</td>\n",
       "      <td>79.923752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>23.397105</td>\n",
       "      <td>1600.733519</td>\n",
       "      <td>19587.067856</td>\n",
       "      <td>1.024215e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>1.308384</td>\n",
       "      <td>68.415879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother</td>\n",
       "      <td>5.545177</td>\n",
       "      <td>63.887324</td>\n",
       "      <td>19587.067856</td>\n",
       "      <td>1.024215e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.220332</td>\n",
       "      <td>11.521241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>arriving</td>\n",
       "      <td>15.249238</td>\n",
       "      <td>28.419034</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.862418</td>\n",
       "      <td>1.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>living</td>\n",
       "      <td>85.322770</td>\n",
       "      <td>192.891917</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>1.046179</td>\n",
       "      <td>2.260732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>toiletry</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>11.090355</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>3.702088</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>tram</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.199881</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3184 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  old_frequency  new_frequency  old_sum_count  new_sum_count  \\\n",
       "0       bedroom      14.203870     516.607518   19587.067856   1.024215e+06   \n",
       "1     centrally       1.386294     129.330841   19587.067856   1.024215e+06   \n",
       "2         quiet      42.281978    3379.334336   19587.067856   1.024215e+06   \n",
       "3          many      23.397105    1600.733519   19587.067856   1.024215e+06   \n",
       "4        mother       5.545177      63.887324   19587.067856   1.024215e+06   \n",
       "...         ...            ...            ...            ...            ...   \n",
       "3179   arriving      15.249238      28.419034  155587.453652   3.362156e+05   \n",
       "3180     living      85.322770     192.891917  155587.453652   3.362156e+05   \n",
       "3181   toiletry       1.386294      11.090355  155587.453652   3.362156e+05   \n",
       "3182   sympathy       0.000000       0.693147  155587.453652   3.362156e+05   \n",
       "3183       tram       0.000000      21.199881  155587.453652   3.362156e+05   \n",
       "\n",
       "       city  Ofrequency  Nfrequency      freq         gain   licia_gain  \n",
       "0     tokyo    0.000725    0.000504  0.000615     0.695556    36.370898  \n",
       "1     tokyo    0.000071    0.000126  0.000099     1.784124    93.292481  \n",
       "2     tokyo    0.002159    0.003299  0.002729     1.528460    79.923752  \n",
       "3     tokyo    0.001195    0.001563  0.001379     1.308384    68.415879  \n",
       "4     tokyo    0.000283    0.000062  0.000173     0.220332    11.521241  \n",
       "...     ...         ...         ...       ...          ...          ...  \n",
       "3179    rio    0.000098    0.000085  0.000091     0.862418     1.863636  \n",
       "3180    rio    0.000548    0.000574  0.000561     1.046179     2.260732  \n",
       "3181    rio    0.000009    0.000033  0.000021     3.702088     8.000000  \n",
       "3182    rio    0.000000    0.000002  0.000001  1000.000000  1000.000000  \n",
       "3183    rio    0.000000    0.000063  0.000032  1000.000000  1000.000000  \n",
       "\n",
       "[3184 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_out.to_csv(r'~/Downloads/big_out.csv', index = False)\n",
    "big_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gain_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedroom</td>\n",
       "      <td>1.173187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cooked</td>\n",
       "      <td>0.775241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conveniently</td>\n",
       "      <td>0.929081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>centrally</td>\n",
       "      <td>2.062954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>towel</td>\n",
       "      <td>1.115661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>useful</td>\n",
       "      <td>0.760226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>home</td>\n",
       "      <td>0.916048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>room</td>\n",
       "      <td>1.253097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>fridge</td>\n",
       "      <td>0.743531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>toiletry</td>\n",
       "      <td>1.149748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  gain_mean\n",
       "0         bedroom   1.173187\n",
       "1          cooked   0.775241\n",
       "2    conveniently   0.929081\n",
       "3       centrally   2.062954\n",
       "4           towel   1.115661\n",
       "..            ...        ...\n",
       "316        useful   0.760226\n",
       "317          home   0.916048\n",
       "318          room   1.253097\n",
       "319        fridge   0.743531\n",
       "320      toiletry   1.149748\n",
       "\n",
       "[321 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"word\", \"gain_mean\"]\n",
    "mean_gain = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for dic in dictionary_words:\n",
    "    dic_rows = big_out[big_out['word'] == dic]\n",
    "    dic_rows = dic_rows[dic_rows['gain'] != 1000]\n",
    "    f = dic_rows['gain'].mean()\n",
    "    mean_gain = mean_gain.append({'word': dic, 'gain_mean': f}, ignore_index=True)\n",
    "\n",
    "mean_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gain_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>0.130907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generosity</td>\n",
       "      <td>0.300439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>email</td>\n",
       "      <td>0.313008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>discrete</td>\n",
       "      <td>0.367177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>punctual</td>\n",
       "      <td>0.367652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cabin</td>\n",
       "      <td>0.486632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hers</td>\n",
       "      <td>0.491176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>delightful</td>\n",
       "      <td>0.497754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interesting</td>\n",
       "      <td>0.502746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>waiting</td>\n",
       "      <td>0.503967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>company</td>\n",
       "      <td>0.525978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apt</td>\n",
       "      <td>0.551844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>served</td>\n",
       "      <td>0.565020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chat</td>\n",
       "      <td>0.573391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>departure</td>\n",
       "      <td>0.586083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>conversation</td>\n",
       "      <td>0.589198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arrival</td>\n",
       "      <td>0.604337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tram</td>\n",
       "      <td>0.606191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>story</td>\n",
       "      <td>0.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>river</td>\n",
       "      <td>0.614001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shampoo</td>\n",
       "      <td>2.129073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>checkout</td>\n",
       "      <td>2.133913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>checking</td>\n",
       "      <td>2.206137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>responded</td>\n",
       "      <td>2.209205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>check</td>\n",
       "      <td>2.289622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>responsive</td>\n",
       "      <td>2.352431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transit</td>\n",
       "      <td>2.377757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>parking</td>\n",
       "      <td>2.423737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>replied</td>\n",
       "      <td>2.442707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>responds</td>\n",
       "      <td>2.612080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>respond</td>\n",
       "      <td>2.643426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>reply</td>\n",
       "      <td>2.696547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>communicator</td>\n",
       "      <td>2.918442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>described</td>\n",
       "      <td>3.026049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>communicate</td>\n",
       "      <td>3.260602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>checkin</td>\n",
       "      <td>3.609414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>response</td>\n",
       "      <td>3.706827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>communication</td>\n",
       "      <td>4.179113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>communicative</td>\n",
       "      <td>4.314105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>walkable</td>\n",
       "      <td>9.103731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  gain_mean\n",
       "0        sympathy   0.130907\n",
       "1      generosity   0.300439\n",
       "2           email   0.313008\n",
       "3        discrete   0.367177\n",
       "4        punctual   0.367652\n",
       "5           cabin   0.486632\n",
       "6            hers   0.491176\n",
       "7      delightful   0.497754\n",
       "8     interesting   0.502746\n",
       "9         waiting   0.503967\n",
       "10        company   0.525978\n",
       "11            apt   0.551844\n",
       "12         served   0.565020\n",
       "13           chat   0.573391\n",
       "14      departure   0.586083\n",
       "15   conversation   0.589198\n",
       "16        arrival   0.604337\n",
       "17           tram   0.606191\n",
       "18          story   0.612800\n",
       "19          river   0.614001\n",
       "20        shampoo   2.129073\n",
       "21       checkout   2.133913\n",
       "22       checking   2.206137\n",
       "23      responded   2.209205\n",
       "24          check   2.289622\n",
       "25     responsive   2.352431\n",
       "26        transit   2.377757\n",
       "27        parking   2.423737\n",
       "28        replied   2.442707\n",
       "29       responds   2.612080\n",
       "30        respond   2.643426\n",
       "31          reply   2.696547\n",
       "32   communicator   2.918442\n",
       "33      described   3.026049\n",
       "34    communicate   3.260602\n",
       "35        checkin   3.609414\n",
       "36       response   3.706827\n",
       "37  communication   4.179113\n",
       "38  communicative   4.314105\n",
       "39       walkable   9.103731"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = mean_gain.nlargest(20, 'gain_mean')\n",
    "bottom = mean_gain.nsmallest(20, 'gain_mean')\n",
    "top = top.sort_values(by = 'gain_mean', ascending=True)\n",
    "li = pd.concat([bottom, top], ignore_index=True)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>old_frequency</th>\n",
       "      <th>new_frequency</th>\n",
       "      <th>old_sum_count</th>\n",
       "      <th>new_sum_count</th>\n",
       "      <th>city</th>\n",
       "      <th>Ofrequency</th>\n",
       "      <th>Nfrequency</th>\n",
       "      <th>freq</th>\n",
       "      <th>gain</th>\n",
       "      <th>licia_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28749.413958</td>\n",
       "      <td>2.849399e+05</td>\n",
       "      <td>santiago</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>152972.974940</td>\n",
       "      <td>5.842802e+05</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.261814</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generosity</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>29943.177707</td>\n",
       "      <td>7.425888e+05</td>\n",
       "      <td>taipei</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.241936</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generosity</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>18882.041536</td>\n",
       "      <td>4.234295e+05</td>\n",
       "      <td>singapore</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.178372</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generosity</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>12.476649</td>\n",
       "      <td>53601.102349</td>\n",
       "      <td>1.137558e+06</td>\n",
       "      <td>mexico_city</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.424075</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>walkable</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>142.330738</td>\n",
       "      <td>18882.041536</td>\n",
       "      <td>4.234295e+05</td>\n",
       "      <td>singapore</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>4.578372</td>\n",
       "      <td>102.669925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>walkable</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>168.840230</td>\n",
       "      <td>80611.444300</td>\n",
       "      <td>7.503074e+05</td>\n",
       "      <td>hong_kong</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>5.234051</td>\n",
       "      <td>48.716993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>walkable</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>561.397100</td>\n",
       "      <td>53601.102349</td>\n",
       "      <td>1.137558e+06</td>\n",
       "      <td>mexico_city</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>7.632643</td>\n",
       "      <td>161.984963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>walkable</td>\n",
       "      <td>15.654703</td>\n",
       "      <td>163.295053</td>\n",
       "      <td>152972.974940</td>\n",
       "      <td>5.842802e+05</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>2.731000</td>\n",
       "      <td>10.431054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>walkable</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>36.449118</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>24.334270</td>\n",
       "      <td>52.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  old_frequency  new_frequency  old_sum_count  new_sum_count  \\\n",
       "0      sympathy       0.693147       0.000000   28749.413958   2.849399e+05   \n",
       "1      sympathy       0.693147       0.693147  152972.974940   5.842802e+05   \n",
       "2    generosity       0.693147       4.158883   29943.177707   7.425888e+05   \n",
       "3    generosity       0.693147       2.772589   18882.041536   4.234295e+05   \n",
       "4    generosity       1.386294      12.476649   53601.102349   1.137558e+06   \n",
       "..          ...            ...            ...            ...            ...   \n",
       "315    walkable       1.386294     142.330738   18882.041536   4.234295e+05   \n",
       "316    walkable       3.465736     168.840230   80611.444300   7.503074e+05   \n",
       "317    walkable       3.465736     561.397100   53601.102349   1.137558e+06   \n",
       "318    walkable      15.654703     163.295053  152972.974940   5.842802e+05   \n",
       "319    walkable       0.693147      36.449118  155587.453652   3.362156e+05   \n",
       "\n",
       "             city  Ofrequency  Nfrequency      freq       gain  licia_gain  \n",
       "0        santiago    0.000024    0.000000  0.000012   0.000000    0.000000  \n",
       "1    buenos_aires    0.000005    0.000001  0.000003   0.261814    1.000000  \n",
       "2          taipei    0.000023    0.000006  0.000014   0.241936    6.000000  \n",
       "3       singapore    0.000037    0.000007  0.000022   0.178372    4.000000  \n",
       "4     mexico_city    0.000026    0.000011  0.000018   0.424075    9.000000  \n",
       "..            ...         ...         ...       ...        ...         ...  \n",
       "315     singapore    0.000073    0.000336  0.000205   4.578372  102.669925  \n",
       "316     hong_kong    0.000043    0.000225  0.000134   5.234051   48.716993  \n",
       "317   mexico_city    0.000065    0.000494  0.000279   7.632643  161.984963  \n",
       "318  buenos_aires    0.000102    0.000279  0.000191   2.731000   10.431054  \n",
       "319           rio    0.000004    0.000108  0.000056  24.334270   52.584963  \n",
       "\n",
       "[320 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_rows = pd.DataFrame()\n",
    "for w in li['word']:\n",
    "#     print(w)\n",
    "    temp = big_out[big_out['word'] == w]\n",
    "    temp = temp[temp['gain'] != 1000]\n",
    "    main_rows = pd.concat([main_rows, temp], ignore_index=True) \n",
    "\n",
    "main_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_rows.to_csv(r'~/Downloads/main_rows.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>old_frequency</th>\n",
       "      <th>new_frequency</th>\n",
       "      <th>old_sum_count</th>\n",
       "      <th>new_sum_count</th>\n",
       "      <th>city</th>\n",
       "      <th>Ofrequency</th>\n",
       "      <th>Nfrequency</th>\n",
       "      <th>freq</th>\n",
       "      <th>gain</th>\n",
       "      <th>licia_gain</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28749.413958</td>\n",
       "      <td>2.849399e+05</td>\n",
       "      <td>santiago</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>152972.974940</td>\n",
       "      <td>5.842802e+05</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.261814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generosity</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>29943.177707</td>\n",
       "      <td>7.425888e+05</td>\n",
       "      <td>taipei</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.241936</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generosity</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>18882.041536</td>\n",
       "      <td>4.234295e+05</td>\n",
       "      <td>singapore</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.178372</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generosity</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>12.476649</td>\n",
       "      <td>53601.102349</td>\n",
       "      <td>1.137558e+06</td>\n",
       "      <td>mexico_city</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.424075</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>walkable</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>142.330738</td>\n",
       "      <td>18882.041536</td>\n",
       "      <td>4.234295e+05</td>\n",
       "      <td>singapore</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>4.578372</td>\n",
       "      <td>102.669925</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>walkable</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>168.840230</td>\n",
       "      <td>80611.444300</td>\n",
       "      <td>7.503074e+05</td>\n",
       "      <td>hong_kong</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>5.234051</td>\n",
       "      <td>48.716993</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>walkable</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>561.397100</td>\n",
       "      <td>53601.102349</td>\n",
       "      <td>1.137558e+06</td>\n",
       "      <td>mexico_city</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>7.632643</td>\n",
       "      <td>161.984963</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>walkable</td>\n",
       "      <td>15.654703</td>\n",
       "      <td>163.295053</td>\n",
       "      <td>152972.974940</td>\n",
       "      <td>5.842802e+05</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>2.731000</td>\n",
       "      <td>10.431054</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>walkable</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>36.449118</td>\n",
       "      <td>155587.453652</td>\n",
       "      <td>3.362156e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>24.334270</td>\n",
       "      <td>52.584963</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  old_frequency  new_frequency  old_sum_count  new_sum_count  \\\n",
       "0      sympathy       0.693147       0.000000   28749.413958   2.849399e+05   \n",
       "1      sympathy       0.693147       0.693147  152972.974940   5.842802e+05   \n",
       "2    generosity       0.693147       4.158883   29943.177707   7.425888e+05   \n",
       "3    generosity       0.693147       2.772589   18882.041536   4.234295e+05   \n",
       "4    generosity       1.386294      12.476649   53601.102349   1.137558e+06   \n",
       "..          ...            ...            ...            ...            ...   \n",
       "315    walkable       1.386294     142.330738   18882.041536   4.234295e+05   \n",
       "316    walkable       3.465736     168.840230   80611.444300   7.503074e+05   \n",
       "317    walkable       3.465736     561.397100   53601.102349   1.137558e+06   \n",
       "318    walkable      15.654703     163.295053  152972.974940   5.842802e+05   \n",
       "319    walkable       0.693147      36.449118  155587.453652   3.362156e+05   \n",
       "\n",
       "             city  Ofrequency  Nfrequency      freq       gain  licia_gain  \\\n",
       "0        santiago    0.000024    0.000000  0.000012   0.000000    0.000000   \n",
       "1    buenos_aires    0.000005    0.000001  0.000003   0.261814    1.000000   \n",
       "2          taipei    0.000023    0.000006  0.000014   0.241936    6.000000   \n",
       "3       singapore    0.000037    0.000007  0.000022   0.178372    4.000000   \n",
       "4     mexico_city    0.000026    0.000011  0.000018   0.424075    9.000000   \n",
       "..            ...         ...         ...       ...        ...         ...   \n",
       "315     singapore    0.000073    0.000336  0.000205   4.578372  102.669925   \n",
       "316     hong_kong    0.000043    0.000225  0.000134   5.234051   48.716993   \n",
       "317   mexico_city    0.000065    0.000494  0.000279   7.632643  161.984963   \n",
       "318  buenos_aires    0.000102    0.000279  0.000191   2.731000   10.431054   \n",
       "319           rio    0.000004    0.000108  0.000056  24.334270   52.584963   \n",
       "\n",
       "          cat  \n",
       "0      social  \n",
       "1      social  \n",
       "2    business  \n",
       "3    business  \n",
       "4    business  \n",
       "..        ...  \n",
       "315  business  \n",
       "316  business  \n",
       "317  business  \n",
       "318  business  \n",
       "319  business  \n",
       "\n",
       "[320 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cat_lev1(word):\n",
    "    ind = dictionary.index[dictionary['word']==word]\n",
    "    return dictionary.loc[ind, 'cat_lev1'].tolist()[0]\n",
    "\n",
    "main_rows['cat'] = main_rows['word'].apply(lambda x: get_cat_lev1(x))\n",
    "main_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_rows.to_csv(r'~/Downloads/MAIN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE LATER\n",
    "top['temp'] =  top['word'].apply(lambda x: get_cat_lev1(x))\n",
    "bottom['temp'] =  bottom['word'].apply(lambda x: get_cat_lev1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_out.to_csv(r'~/Downloads/big_out.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
