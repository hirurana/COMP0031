{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer() #create lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shirinharandi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv('../data/processedDict.csv')\n",
    "dictionary['word'] = dictionary['word'].apply(lambda x: lem.lemmatize(x, pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE LATER\n",
    "# mask = (reviews['date'] >= '2013-01-01') & (reviews['date'] < '2014-01-01')\n",
    "# reviews = reviews.loc[mask].copy()\n",
    "# reviews[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_trends_nice_og(reviews):\n",
    "    \n",
    "    def get_unique_words(rev):\n",
    "        \n",
    "        allwords = rev['comments'].tolist()\n",
    "        allwords = \" \".join(allwords)\n",
    "        unique_words = set(allwords.split(' '))\n",
    "\n",
    "        unique_words = list(unique_words)\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "\n",
    "        ls = []\n",
    "        for word in unique_words:\n",
    "            word = ''.join([i for i in word if not i.isdigit()])\n",
    "            ls += [word]\n",
    "        unique_words= ls\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "        unique_words = list(dict.fromkeys(unique_words))\n",
    "        return unique_words\n",
    "    \n",
    "    def get_masked_reviews(start_year, end_year):\n",
    "        mask = (reviews['date'] >= start_year) & (reviews['date'] < end_year)\n",
    "        return reviews.loc[mask].copy()\n",
    "    \n",
    "#     def get_reviews_list(rev):\n",
    "        \n",
    "    \n",
    "    old_reviews =  get_masked_reviews('2013-01-01', '2015-01-01')\n",
    "#     print(old_reviews)\n",
    "    new_reviews =  get_masked_reviews('2017-01-01', '2019-01-01')\n",
    "\n",
    "    start_year_words = get_unique_words(old_reviews)\n",
    "    end_year_words = get_unique_words(new_reviews)\n",
    "    \n",
    "    old_reviews_list = old_reviews['comments'].tolist()\n",
    "    new_reviews_list = new_reviews['comments'].tolist()\n",
    "\n",
    "#     print(new_reviews_list)\n",
    "    \n",
    "    def get_freq(word, rev):\n",
    "        total = 0.0\n",
    "        rev = list(rev)\n",
    "        for r in rev:\n",
    "            r = r.split()\n",
    "            total += math.log(1 + r.count(word))\n",
    "        return total\n",
    "\n",
    "    column_names = [\"word\", \"old_frequency\", \"new_frequency\"]\n",
    "    out = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    old_total = 0.0\n",
    "    for word in start_year_words:\n",
    "        f = get_freq(word, old_reviews_list)\n",
    "        old_total += f\n",
    "        out = out.append({'word': word, 'old_frequency': f, \"new_frequency\": 0.0}, ignore_index=True)\n",
    "        \n",
    "    new_total = 0.0\n",
    "    for word in end_year_words:\n",
    "        f = get_freq(word, new_reviews_list)\n",
    "        new_total += f\n",
    "        if word in start_year_words:\n",
    "            ind = out.index[out['word']==word]\n",
    "            out.loc[ind,\"new_frequency\"] = f\n",
    "        else:\n",
    "            out = out.append({'word': word, 'old_frequency': 0.0, 'new_frequency': f}, ignore_index=True)\n",
    "    \n",
    "    out[\"old_sum_count\"] = old_total\n",
    "    out[\"new_sum_count\"] = new_total\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "killme = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trends_nice(reviews):\n",
    "    \n",
    "    def get_unique_words(rev):\n",
    "        \n",
    "        allwords = rev['comments'].tolist()\n",
    "        allwords = \" \".join(allwords)\n",
    "        unique_words = set(allwords.split(' '))\n",
    "\n",
    "        unique_words = list(unique_words)\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "\n",
    "        ls = []\n",
    "        for word in unique_words:\n",
    "            word = ''.join([i for i in word if not i.isdigit()])\n",
    "            ls += [word]\n",
    "        unique_words= ls\n",
    "        unique_words = [string for string in unique_words if string != \"\"]\n",
    "        unique_words = list(dict.fromkeys(unique_words))\n",
    "        return unique_words\n",
    "    \n",
    "    def get_masked_reviews(start_year, end_year):\n",
    "        mask = (reviews['date'] >= start_year) & (reviews['date'] < end_year)\n",
    "        return reviews.loc[mask].copy()\n",
    "    \n",
    "#     def get_reviews_list(rev):\n",
    "        \n",
    "    \n",
    "    old_reviews =  get_masked_reviews('2013-01-01', '2015-01-01')\n",
    "#     print(old_reviews)\n",
    "    new_reviews =  get_masked_reviews('2017-01-01', '2019-01-01')\n",
    "\n",
    "    start_year_words = get_unique_words(old_reviews)\n",
    "    end_year_words = get_unique_words(new_reviews)\n",
    "    \n",
    "    in_first = set(start_year_words)\n",
    "    in_second = set(end_year_words)\n",
    "\n",
    "    in_second_but_not_in_first = in_second - in_first\n",
    "\n",
    "    total_words_in_reviews = start_year_words + list(in_second_but_not_in_first)\n",
    "    killme = total_words_in_reviews\n",
    "    \n",
    "    old_reviews_list = old_reviews['comments'].tolist()\n",
    "    new_reviews_list = new_reviews['comments'].tolist()\n",
    "\n",
    "\n",
    "    def get_freq(word, rev):\n",
    "        total = 0.0\n",
    "        rev = list(rev)\n",
    "        for r in rev:\n",
    "            r = r.split()\n",
    "            total += math.log(1 + r.count(word))\n",
    "        return total\n",
    "\n",
    "    column_names = [\"word\", \"old_frequency\", \"new_frequency\"]\n",
    "    out = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    old_total = 0.0\n",
    "    new_total = 0.0\n",
    "    for word in total_words_in_reviews:\n",
    "        f = get_freq(word, old_reviews_list)\n",
    "        old_total += f\n",
    "#         print(f)\n",
    "#         print(word)\n",
    "        f2 = get_freq(word, new_reviews_list)\n",
    "        new_total += f2\n",
    "        out = out.append({'word': word, 'old_frequency': f, \"new_frequency\": f2}, ignore_index=True)\n",
    "        \n",
    "    out[\"old_sum_count\"] = old_total\n",
    "    out[\"new_sum_count\"] = new_total\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_words = dictionary['word'].tolist()\n",
    "dictionary_words = list(set(dictionary_words))\n",
    "# dictionary_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "cities = [\"tokyo\", \"belize\", \"santiago\", \"taipei\", \"singapore\", \"beijing\", \"hong_kong\", \"mexico_city\", \"buenos_aires\", \"rio\"]\n",
    "# cities = [\"manchester\", \"tokyo\"]\n",
    "\n",
    "column_names = [\"word\", \"old_frequency\", \"new_frequency\",\"old_sum_count\", \"new_sum_count\",\"city\", \"Ofrequency\", \"Nfrequency\",\"freq\", \"gain\", \"licia_gain\"]\n",
    "big_out = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for c in cities: \n",
    "    path = \"/Users/shirinharandi/Desktop/COMP0031/Data/en_reviews/{}_en.csv\".format(c)\n",
    "    filepath = path\n",
    "    city_name = c\n",
    "    reviews = pd.read_csv(filepath)\n",
    "\n",
    "    table = str.maketrans('', '', string.punctuation) #mapping to strip punctuation in review\n",
    "\n",
    "    #strip punct of each review -> lemmatise -> output is list of words so join into sentences\n",
    "    reviews['comments'] = reviews.comments.apply(lambda review: ' '.join(map(str, [lem.lemmatize(word.translate(table), pos='n') for word in review.lower().split()])))\n",
    "    reviews['date'] = pd.to_datetime(reviews['date'])\n",
    "    \n",
    "    out = get_trends_nice_og(reviews)\n",
    "    \n",
    "    test = out[out['word'].isin(dictionary_words)]\n",
    "\n",
    "    test['city'] = city_name\n",
    "    test['Ofrequency'] = test['old_frequency'] / test['old_sum_count']\n",
    "    test['Nfrequency'] = test['new_frequency'] / test['new_sum_count']\n",
    "    test['freq'] = (test['Nfrequency'] + test['Ofrequency'])/2\n",
    "    test['gain'] = np.where(test['Ofrequency'] == 0, 1000 ,test['Nfrequency'] / test['Ofrequency'])\n",
    "    test['licia_gain'] = np.where(test['Ofrequency'] == 0, 1000 ,test['new_frequency'] / test['old_frequency'])\n",
    "    \n",
    "#     print(test)\n",
    "    big_out = pd.concat([big_out, test], ignore_index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>old_frequency</th>\n",
       "      <th>new_frequency</th>\n",
       "      <th>old_sum_count</th>\n",
       "      <th>new_sum_count</th>\n",
       "      <th>city</th>\n",
       "      <th>Ofrequency</th>\n",
       "      <th>Nfrequency</th>\n",
       "      <th>freq</th>\n",
       "      <th>gain</th>\n",
       "      <th>licia_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walkable</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>579.418927</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>6.190566</td>\n",
       "      <td>208.981203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>share</td>\n",
       "      <td>32.290235</td>\n",
       "      <td>372.063688</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.341326</td>\n",
       "      <td>11.522483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mother</td>\n",
       "      <td>17.734145</td>\n",
       "      <td>143.547133</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.239777</td>\n",
       "      <td>8.094393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meal</td>\n",
       "      <td>30.210794</td>\n",
       "      <td>478.927265</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.469603</td>\n",
       "      <td>15.852853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min</td>\n",
       "      <td>234.923769</td>\n",
       "      <td>4131.184119</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.520920</td>\n",
       "      <td>17.585211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>transport</td>\n",
       "      <td>117.495223</td>\n",
       "      <td>224.409787</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>1.129775</td>\n",
       "      <td>1.909948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>property</td>\n",
       "      <td>98.482401</td>\n",
       "      <td>196.124344</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1.177995</td>\n",
       "      <td>1.991466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>question</td>\n",
       "      <td>523.523122</td>\n",
       "      <td>871.247441</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.984410</td>\n",
       "      <td>1.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>hot</td>\n",
       "      <td>236.760745</td>\n",
       "      <td>379.309944</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.947665</td>\n",
       "      <td>1.602081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>towel</td>\n",
       "      <td>202.582427</td>\n",
       "      <td>311.655651</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.910005</td>\n",
       "      <td>1.538414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3195 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  old_frequency  new_frequency  old_sum_count  new_sum_count  \\\n",
       "0      walkable       2.772589     579.418927   84514.056407   2.853027e+06   \n",
       "1         share      32.290235     372.063688   84514.056407   2.853027e+06   \n",
       "2        mother      17.734145     143.547133   84514.056407   2.853027e+06   \n",
       "3          meal      30.210794     478.927265   84514.056407   2.853027e+06   \n",
       "4           min     234.923769    4131.184119   84514.056407   2.853027e+06   \n",
       "...         ...            ...            ...            ...            ...   \n",
       "3190  transport     117.495223     224.409787  462327.771895   7.815908e+05   \n",
       "3191   property      98.482401     196.124344  462327.771895   7.815908e+05   \n",
       "3192   question     523.523122     871.247441  462327.771895   7.815908e+05   \n",
       "3193        hot     236.760745     379.309944  462327.771895   7.815908e+05   \n",
       "3194      towel     202.582427     311.655651  462327.771895   7.815908e+05   \n",
       "\n",
       "       city  Ofrequency  Nfrequency      freq      gain  licia_gain  \n",
       "0     tokyo    0.000033    0.000203  0.000118  6.190566  208.981203  \n",
       "1     tokyo    0.000382    0.000130  0.000256  0.341326   11.522483  \n",
       "2     tokyo    0.000210    0.000050  0.000130  0.239777    8.094393  \n",
       "3     tokyo    0.000357    0.000168  0.000263  0.469603   15.852853  \n",
       "4     tokyo    0.002780    0.001448  0.002114  0.520920   17.585211  \n",
       "...     ...         ...         ...       ...       ...         ...  \n",
       "3190    rio    0.000254    0.000287  0.000271  1.129775    1.909948  \n",
       "3191    rio    0.000213    0.000251  0.000232  1.177995    1.991466  \n",
       "3192    rio    0.001132    0.001115  0.001124  0.984410    1.664200  \n",
       "3193    rio    0.000512    0.000485  0.000499  0.947665    1.602081  \n",
       "3194    rio    0.000438    0.000399  0.000418  0.910005    1.538414  \n",
       "\n",
       "[3195 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_out.to_csv(r'~/Downloads/big_out.csv', index = False)\n",
    "big_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gain_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connected</td>\n",
       "      <td>1.470889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walkable</td>\n",
       "      <td>3.921430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appartment</td>\n",
       "      <td>0.952284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wifi</td>\n",
       "      <td>1.011630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>helpful</td>\n",
       "      <td>0.852944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.934639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>timely</td>\n",
       "      <td>2.508729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>responded</td>\n",
       "      <td>1.780466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>cosy</td>\n",
       "      <td>0.970206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>0.700145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  gain_mean\n",
       "0     connected   1.470889\n",
       "1      walkable   3.921430\n",
       "2    appartment   0.952284\n",
       "3          wifi   1.011630\n",
       "4       helpful   0.852944\n",
       "..          ...        ...\n",
       "316       sweet   0.934639\n",
       "317      timely   2.508729\n",
       "318   responded   1.780466\n",
       "319        cosy   0.970206\n",
       "320     relaxed   0.700145\n",
       "\n",
       "[321 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"word\", \"gain_mean\"]\n",
    "mean_gain = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for dic in dictionary_words:\n",
    "    dic_rows = big_out[big_out['word'] == dic]\n",
    "    dic_rows = dic_rows[dic_rows['gain'] != 1000]\n",
    "    f = dic_rows['gain'].mean()\n",
    "    mean_gain = mean_gain.append({'word': dic, 'gain_mean': f}, ignore_index=True)\n",
    "\n",
    "mean_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gain_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>punctuality</td>\n",
       "      <td>0.153395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>email</td>\n",
       "      <td>0.221603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generosity</td>\n",
       "      <td>0.339193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>discrete</td>\n",
       "      <td>0.413901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrival</td>\n",
       "      <td>0.476872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>punctual</td>\n",
       "      <td>0.492361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>delightful</td>\n",
       "      <td>0.520771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>waiting</td>\n",
       "      <td>0.523889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interesting</td>\n",
       "      <td>0.539752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hers</td>\n",
       "      <td>0.545081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chatting</td>\n",
       "      <td>0.552774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chat</td>\n",
       "      <td>0.556055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>company</td>\n",
       "      <td>0.559230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>welcome</td>\n",
       "      <td>0.565113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arrived</td>\n",
       "      <td>0.569904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>explained</td>\n",
       "      <td>0.571813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>moment</td>\n",
       "      <td>0.575025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>conversation</td>\n",
       "      <td>0.576927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>girlfriend</td>\n",
       "      <td>0.577106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>daughter</td>\n",
       "      <td>0.590688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>prompt</td>\n",
       "      <td>1.950996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>communicating</td>\n",
       "      <td>2.042791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>amenity</td>\n",
       "      <td>2.088263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pillow</td>\n",
       "      <td>2.103678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>parking</td>\n",
       "      <td>2.123234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>check</td>\n",
       "      <td>2.191408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>quick</td>\n",
       "      <td>2.202545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>reply</td>\n",
       "      <td>2.257113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>responsive</td>\n",
       "      <td>2.293763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>communicator</td>\n",
       "      <td>2.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>timely</td>\n",
       "      <td>2.508729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>communicative</td>\n",
       "      <td>2.515839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>respond</td>\n",
       "      <td>2.549105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>communication</td>\n",
       "      <td>3.061810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>communicate</td>\n",
       "      <td>3.234345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>responds</td>\n",
       "      <td>3.262151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>checkin</td>\n",
       "      <td>3.891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>walkable</td>\n",
       "      <td>3.921430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>transit</td>\n",
       "      <td>4.010444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>response</td>\n",
       "      <td>6.378626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  gain_mean\n",
       "0     punctuality   0.153395\n",
       "1           email   0.221603\n",
       "2      generosity   0.339193\n",
       "3        discrete   0.413901\n",
       "4         arrival   0.476872\n",
       "5        punctual   0.492361\n",
       "6      delightful   0.520771\n",
       "7         waiting   0.523889\n",
       "8     interesting   0.539752\n",
       "9            hers   0.545081\n",
       "10       chatting   0.552774\n",
       "11           chat   0.556055\n",
       "12        company   0.559230\n",
       "13        welcome   0.565113\n",
       "14        arrived   0.569904\n",
       "15      explained   0.571813\n",
       "16         moment   0.575025\n",
       "17   conversation   0.576927\n",
       "18     girlfriend   0.577106\n",
       "19       daughter   0.590688\n",
       "20         prompt   1.950996\n",
       "21  communicating   2.042791\n",
       "22        amenity   2.088263\n",
       "23         pillow   2.103678\n",
       "24        parking   2.123234\n",
       "25          check   2.191408\n",
       "26          quick   2.202545\n",
       "27          reply   2.257113\n",
       "28     responsive   2.293763\n",
       "29   communicator   2.365574\n",
       "30         timely   2.508729\n",
       "31  communicative   2.515839\n",
       "32        respond   2.549105\n",
       "33  communication   3.061810\n",
       "34    communicate   3.234345\n",
       "35       responds   3.262151\n",
       "36        checkin   3.891143\n",
       "37       walkable   3.921430\n",
       "38        transit   4.010444\n",
       "39       response   6.378626"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = mean_gain.nlargest(20, 'gain_mean')\n",
    "bottom = mean_gain.nsmallest(20, 'gain_mean')\n",
    "top = top.sort_values(by = 'gain_mean', ascending=True)\n",
    "li = pd.concat([bottom, top], ignore_index=True)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>old_frequency</th>\n",
       "      <th>new_frequency</th>\n",
       "      <th>old_sum_count</th>\n",
       "      <th>new_sum_count</th>\n",
       "      <th>city</th>\n",
       "      <th>Ofrequency</th>\n",
       "      <th>Nfrequency</th>\n",
       "      <th>freq</th>\n",
       "      <th>gain</th>\n",
       "      <th>licia_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>punctuality</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>426329.038844</td>\n",
       "      <td>1.389642e+06</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.975910e-07</td>\n",
       "      <td>2.124646e-06</td>\n",
       "      <td>0.306791</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>punctuality</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.496275e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>email</td>\n",
       "      <td>27.843670</td>\n",
       "      <td>280.973725</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>9.848269e-05</td>\n",
       "      <td>2.139694e-04</td>\n",
       "      <td>0.298925</td>\n",
       "      <td>10.091117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>13.862944</td>\n",
       "      <td>85.728235</td>\n",
       "      <td>43668.014643</td>\n",
       "      <td>7.311018e+05</td>\n",
       "      <td>belize</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>1.172590e-04</td>\n",
       "      <td>2.173606e-04</td>\n",
       "      <td>0.369364</td>\n",
       "      <td>6.183985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email</td>\n",
       "      <td>61.807882</td>\n",
       "      <td>64.292789</td>\n",
       "      <td>87073.800648</td>\n",
       "      <td>6.873788e+05</td>\n",
       "      <td>santiago</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>9.353328e-05</td>\n",
       "      <td>4.016833e-04</td>\n",
       "      <td>0.131768</td>\n",
       "      <td>1.040204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>response</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>200.842783</td>\n",
       "      <td>38248.136582</td>\n",
       "      <td>3.599748e+05</td>\n",
       "      <td>beijing</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>5.579356e-04</td>\n",
       "      <td>2.880290e-04</td>\n",
       "      <td>30.787109</td>\n",
       "      <td>289.754888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>response</td>\n",
       "      <td>66.542129</td>\n",
       "      <td>1308.217847</td>\n",
       "      <td>275248.116448</td>\n",
       "      <td>1.793143e+06</td>\n",
       "      <td>hong_kong</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>7.295671e-04</td>\n",
       "      <td>4.856602e-04</td>\n",
       "      <td>3.017817</td>\n",
       "      <td>19.659994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>response</td>\n",
       "      <td>11.090355</td>\n",
       "      <td>913.581535</td>\n",
       "      <td>183693.466622</td>\n",
       "      <td>3.037567e+06</td>\n",
       "      <td>mexico_city</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>3.007609e-04</td>\n",
       "      <td>1.805676e-04</td>\n",
       "      <td>4.981610</td>\n",
       "      <td>82.376222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>response</td>\n",
       "      <td>59.610658</td>\n",
       "      <td>351.831086</td>\n",
       "      <td>426329.038844</td>\n",
       "      <td>1.389642e+06</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>2.531811e-04</td>\n",
       "      <td>1.965021e-04</td>\n",
       "      <td>1.810724</td>\n",
       "      <td>5.902151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>response</td>\n",
       "      <td>53.372333</td>\n",
       "      <td>180.166151</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>2.305121e-04</td>\n",
       "      <td>1.729774e-04</td>\n",
       "      <td>1.996768</td>\n",
       "      <td>3.375647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  old_frequency  new_frequency  old_sum_count  new_sum_count  \\\n",
       "0    punctuality       1.386294       1.386294  426329.038844   1.389642e+06   \n",
       "1    punctuality       0.693147       0.000000  462327.771895   7.815908e+05   \n",
       "2          email      27.843670     280.973725   84514.056407   2.853027e+06   \n",
       "3          email      13.862944      85.728235   43668.014643   7.311018e+05   \n",
       "4          email      61.807882      64.292789   87073.800648   6.873788e+05   \n",
       "..           ...            ...            ...            ...            ...   \n",
       "365     response       0.693147     200.842783   38248.136582   3.599748e+05   \n",
       "366     response      66.542129    1308.217847  275248.116448   1.793143e+06   \n",
       "367     response      11.090355     913.581535  183693.466622   3.037567e+06   \n",
       "368     response      59.610658     351.831086  426329.038844   1.389642e+06   \n",
       "369     response      53.372333     180.166151  462327.771895   7.815908e+05   \n",
       "\n",
       "             city  Ofrequency    Nfrequency          freq       gain  \\\n",
       "0    buenos_aires    0.000003  9.975910e-07  2.124646e-06   0.306791   \n",
       "1             rio    0.000001  0.000000e+00  7.496275e-07   0.000000   \n",
       "2           tokyo    0.000329  9.848269e-05  2.139694e-04   0.298925   \n",
       "3          belize    0.000317  1.172590e-04  2.173606e-04   0.369364   \n",
       "4        santiago    0.000710  9.353328e-05  4.016833e-04   0.131768   \n",
       "..            ...         ...           ...           ...        ...   \n",
       "365       beijing    0.000018  5.579356e-04  2.880290e-04  30.787109   \n",
       "366     hong_kong    0.000242  7.295671e-04  4.856602e-04   3.017817   \n",
       "367   mexico_city    0.000060  3.007609e-04  1.805676e-04   4.981610   \n",
       "368  buenos_aires    0.000140  2.531811e-04  1.965021e-04   1.810724   \n",
       "369           rio    0.000115  2.305121e-04  1.729774e-04   1.996768   \n",
       "\n",
       "     licia_gain  \n",
       "0      1.000000  \n",
       "1      0.000000  \n",
       "2     10.091117  \n",
       "3      6.183985  \n",
       "4      1.040204  \n",
       "..          ...  \n",
       "365  289.754888  \n",
       "366   19.659994  \n",
       "367   82.376222  \n",
       "368    5.902151  \n",
       "369    3.375647  \n",
       "\n",
       "[370 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_rows = pd.DataFrame()\n",
    "for w in li['word']:\n",
    "#     print(w)\n",
    "    temp = big_out[big_out['word'] == w]\n",
    "    temp = temp[temp['gain'] != 1000]\n",
    "    main_rows = pd.concat([main_rows, temp], ignore_index=True) \n",
    "\n",
    "main_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_rows.to_csv(r'~/Downloads/main_rows.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>old_frequency</th>\n",
       "      <th>new_frequency</th>\n",
       "      <th>old_sum_count</th>\n",
       "      <th>new_sum_count</th>\n",
       "      <th>city</th>\n",
       "      <th>Ofrequency</th>\n",
       "      <th>Nfrequency</th>\n",
       "      <th>freq</th>\n",
       "      <th>gain</th>\n",
       "      <th>licia_gain</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>punctuality</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>426329.038844</td>\n",
       "      <td>1.389642e+06</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.975910e-07</td>\n",
       "      <td>2.124646e-06</td>\n",
       "      <td>0.306791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>punctuality</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.496275e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>email</td>\n",
       "      <td>27.843670</td>\n",
       "      <td>280.973725</td>\n",
       "      <td>84514.056407</td>\n",
       "      <td>2.853027e+06</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>9.848269e-05</td>\n",
       "      <td>2.139694e-04</td>\n",
       "      <td>0.298925</td>\n",
       "      <td>10.091117</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>13.862944</td>\n",
       "      <td>85.728235</td>\n",
       "      <td>43668.014643</td>\n",
       "      <td>7.311018e+05</td>\n",
       "      <td>belize</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>1.172590e-04</td>\n",
       "      <td>2.173606e-04</td>\n",
       "      <td>0.369364</td>\n",
       "      <td>6.183985</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email</td>\n",
       "      <td>61.807882</td>\n",
       "      <td>64.292789</td>\n",
       "      <td>87073.800648</td>\n",
       "      <td>6.873788e+05</td>\n",
       "      <td>santiago</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>9.353328e-05</td>\n",
       "      <td>4.016833e-04</td>\n",
       "      <td>0.131768</td>\n",
       "      <td>1.040204</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>response</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>200.842783</td>\n",
       "      <td>38248.136582</td>\n",
       "      <td>3.599748e+05</td>\n",
       "      <td>beijing</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>5.579356e-04</td>\n",
       "      <td>2.880290e-04</td>\n",
       "      <td>30.787109</td>\n",
       "      <td>289.754888</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>response</td>\n",
       "      <td>66.542129</td>\n",
       "      <td>1308.217847</td>\n",
       "      <td>275248.116448</td>\n",
       "      <td>1.793143e+06</td>\n",
       "      <td>hong_kong</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>7.295671e-04</td>\n",
       "      <td>4.856602e-04</td>\n",
       "      <td>3.017817</td>\n",
       "      <td>19.659994</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>response</td>\n",
       "      <td>11.090355</td>\n",
       "      <td>913.581535</td>\n",
       "      <td>183693.466622</td>\n",
       "      <td>3.037567e+06</td>\n",
       "      <td>mexico_city</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>3.007609e-04</td>\n",
       "      <td>1.805676e-04</td>\n",
       "      <td>4.981610</td>\n",
       "      <td>82.376222</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>response</td>\n",
       "      <td>59.610658</td>\n",
       "      <td>351.831086</td>\n",
       "      <td>426329.038844</td>\n",
       "      <td>1.389642e+06</td>\n",
       "      <td>buenos_aires</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>2.531811e-04</td>\n",
       "      <td>1.965021e-04</td>\n",
       "      <td>1.810724</td>\n",
       "      <td>5.902151</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>response</td>\n",
       "      <td>53.372333</td>\n",
       "      <td>180.166151</td>\n",
       "      <td>462327.771895</td>\n",
       "      <td>7.815908e+05</td>\n",
       "      <td>rio</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>2.305121e-04</td>\n",
       "      <td>1.729774e-04</td>\n",
       "      <td>1.996768</td>\n",
       "      <td>3.375647</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  old_frequency  new_frequency  old_sum_count  new_sum_count  \\\n",
       "0    punctuality       1.386294       1.386294  426329.038844   1.389642e+06   \n",
       "1    punctuality       0.693147       0.000000  462327.771895   7.815908e+05   \n",
       "2          email      27.843670     280.973725   84514.056407   2.853027e+06   \n",
       "3          email      13.862944      85.728235   43668.014643   7.311018e+05   \n",
       "4          email      61.807882      64.292789   87073.800648   6.873788e+05   \n",
       "..           ...            ...            ...            ...            ...   \n",
       "365     response       0.693147     200.842783   38248.136582   3.599748e+05   \n",
       "366     response      66.542129    1308.217847  275248.116448   1.793143e+06   \n",
       "367     response      11.090355     913.581535  183693.466622   3.037567e+06   \n",
       "368     response      59.610658     351.831086  426329.038844   1.389642e+06   \n",
       "369     response      53.372333     180.166151  462327.771895   7.815908e+05   \n",
       "\n",
       "             city  Ofrequency    Nfrequency          freq       gain  \\\n",
       "0    buenos_aires    0.000003  9.975910e-07  2.124646e-06   0.306791   \n",
       "1             rio    0.000001  0.000000e+00  7.496275e-07   0.000000   \n",
       "2           tokyo    0.000329  9.848269e-05  2.139694e-04   0.298925   \n",
       "3          belize    0.000317  1.172590e-04  2.173606e-04   0.369364   \n",
       "4        santiago    0.000710  9.353328e-05  4.016833e-04   0.131768   \n",
       "..            ...         ...           ...           ...        ...   \n",
       "365       beijing    0.000018  5.579356e-04  2.880290e-04  30.787109   \n",
       "366     hong_kong    0.000242  7.295671e-04  4.856602e-04   3.017817   \n",
       "367   mexico_city    0.000060  3.007609e-04  1.805676e-04   4.981610   \n",
       "368  buenos_aires    0.000140  2.531811e-04  1.965021e-04   1.810724   \n",
       "369           rio    0.000115  2.305121e-04  1.729774e-04   1.996768   \n",
       "\n",
       "     licia_gain       cat  \n",
       "0      1.000000  business  \n",
       "1      0.000000  business  \n",
       "2     10.091117  business  \n",
       "3      6.183985  business  \n",
       "4      1.040204  business  \n",
       "..          ...       ...  \n",
       "365  289.754888  business  \n",
       "366   19.659994  business  \n",
       "367   82.376222  business  \n",
       "368    5.902151  business  \n",
       "369    3.375647  business  \n",
       "\n",
       "[370 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cat_lev1(word):\n",
    "    ind = dictionary.index[dictionary['word']==word]\n",
    "    return dictionary.loc[ind, 'cat_lev1'].tolist()[0]\n",
    "\n",
    "main_rows['cat'] = main_rows['word'].apply(lambda x: get_cat_lev1(x))\n",
    "main_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_rows.to_csv(r'~/Downloads/MAIN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
